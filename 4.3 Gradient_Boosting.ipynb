{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import the train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"A_Normalised_train_data.csv\",index_col=0)\n",
    "Y_train = pd.read_csv(\"A_Log_sales_train.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_1 = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA()\n",
    "RG = Model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: PCA\n",
    "# Step 2: Model\n",
    "pipe = Pipeline(steps=[(\"pca\",pca),(\"RG\",RG)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"pca__n_components\": [50, 100,170],\n",
    "    \"RG__learning_rate\":[0.005,0.1,0.5,1,10],\n",
    "    \"RG__n_estimators\":[10,100],\n",
    "    \"RG__min_samples_split\":[0.01*i for i in range(1,3)],\n",
    "    \"RG__ccp_alpha\":[0.005,0.1,0.5,10]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Setup GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_metric = 'neg_mean_squared_error'\n",
    "search = GridSearchCV(pipe,param_grid,\n",
    "                      n_jobs=-1,\n",
    "                      cv=10,\n",
    "                      scoring=score_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.fit(X_train,Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(search.cv_results_)\n",
    "df = df.sort_values(by=['rank_test_score'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Best Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms = pd.DataFrame(df['params'])\n",
    "for i in parms.iloc[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate Model $log(Sales)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pca =parms.iloc[0][0]['pca__n_components']\n",
    "best_lr = parms.iloc[0][0]['RG__learning_rate']\n",
    "best_n_est = parms.iloc[0][0]['RG__n_estimators']\n",
    "best_min_ss=parms.iloc[0][0]['min_samples_split']\n",
    "best_ccp_alpha=parms.iloc[0][0]['ccp_alpha']\n",
    "#best_pca=170\n",
    "#best_lr=0.1\n",
    "#best_n_est=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_2 = GradientBoostingRegressor(learning_rate=best_lr,n_estimators=best_n_est,min_samples_split=best_min_ss,ccp_alpha=best_ccp_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1,X_test1,Y_train1,Y_test1 = train_test_split(X_train,Y_train,test_size=0.2,random_state=132)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 = PCA(n_components=best_pca)\n",
    "pca1.fit(X_train1)\n",
    "PX_train1 = pca1.transform(X_train1)\n",
    "RG1 = Model_2\n",
    "RG1.fit(PX_train1,Y_train1.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2 = PCA(n_components=best_pca)\n",
    "pca2.fit(X_test1)\n",
    "PX_test1 = pca2.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE(RG1.predict(PX_test1),Y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(np.exp(Y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"Predicted_sales\"] = np.exp(RG1.predict(PX_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE(result[\"sales\"],result[\"Predicted_sales\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Model using original sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_3 = GradientBoostingRegressor(learning_rate=best_lr,n_estimators=best_n_est,min_samples_split=best_min_ss,ccp_alpha=best_ccp_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OY_train = pd.read_csv(\"A_sales_train.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2,X_test2,Y_train2,Y_test2 = train_test_split(X_train,OY_train,test_size=0.2,random_state=132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca3 = PCA(n_components=best_pca)\n",
    "pca3.fit(X_train2)\n",
    "PX_train2 = pca3.transform(X_train2)\n",
    "RG2 = Model_3\n",
    "RG2.fit(PX_train2,Y_train2.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca4 = PCA(n_components=best_pca)\n",
    "pca4.fit(X_test2)\n",
    "PX_test2 = pca4.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE(RG2.predict(PX_test2),Y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notably model trained on log(Sales) has lower out-of-sample MSE than model with unmodified Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Inventory Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = result['sales']-result['Predicted_sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price=20\n",
    "Cost=12\n",
    "Salvage=8\n",
    "Over=Cost - Salvage\n",
    "Under=Price - Cost\n",
    "Over, Under"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QQ plot to explore the distribution of residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "scipy.stats.probplot(residual, dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = residual.std()\n",
    "opt_dec_N=np.ceil(sct.norm.ppf(Under/(Under+Over))*s + result['Predicted_sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exponential Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.probplot(residual, dist=\"expon\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dec_E=np.ceil((-result['Predicted_sales'])*np.log(1-(Under/(Under+Over))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empirical Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = residual.shape[0]\n",
    "step=1/size\n",
    "jumps = [step*i for i in range(1,size+1)]\n",
    "Sample = sorted(residual)\n",
    "plt.plot(Sample,jumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv(sample,jump,area):\n",
    "    size = len(sample)\n",
    "    temp=0\n",
    "    i=0\n",
    "    while temp<area:\n",
    "        temp=jump[i]\n",
    "        i+=1\n",
    "    return sample[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = inv(Sample,jumps,2/3)\n",
    "offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dec_B = np.ceil(result['Predicted_sales']+offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Out-of-samples Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max profit for test data set\n",
    "max_profit = result['sales'].sum()*(Price-Cost)\n",
    "max_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profit(demand,inv):\n",
    "    return (Price-Salvage)*np.minimum(demand,inv)-(Cost-Salvage)*inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Profit (Normal)\n",
    "profit_lst_N = profit(result['sales'],opt_dec_N)\n",
    "profit_lst_N.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Profit (Exponential)\n",
    "profit_lst_E = profit(result['sales'],opt_dec_E)\n",
    "profit_lst_E.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Profit (Empirical)\n",
    "profit_lst_B = profit(result['sales'],opt_dec_B)\n",
    "profit_lst_B.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat steps 5,6,7 with 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_4= GradientBoostingRegressor(learning_rate=best_lr,n_estimators=best_n_est,min_samples_split=best_min_ss,ccp_alpha=best_ccp_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "k=10\n",
    "kf = KFold(n_splits=k)\n",
    "X_train_t=X_train.to_numpy()\n",
    "Y_train_t=Y_train.to_numpy()\n",
    "model = []\n",
    "mse_lst = []\n",
    "max_profit_lst = []\n",
    "profit_N_lst = []\n",
    "profit_E_lst = []\n",
    "profit_B_lst = []\n",
    "\n",
    "for train_index,test_index in kf.split(X_train_t):\n",
    "    X_train_K,X_test_K=X_train_t[train_index],X_train_t[test_index]\n",
    "    Y_train_K,Y_test_K=Y_train_t[train_index],Y_train_t[test_index]\n",
    "    \n",
    "    #PCA to transform train data\n",
    "    pca_K1 = PCA(n_components=best_pca)\n",
    "    pca_K1.fit(X_train_K)\n",
    "    PX_train_K = pca_K1.transform(X_train_K)\n",
    "    \n",
    "    #Model\n",
    "    RG_K = Model_4\n",
    "    RG_K.fit(PX_train_K,Y_train_K.ravel())\n",
    "    \n",
    "    #pca to transform test data\n",
    "    pca_K2 = PCA(n_components=best_pca)\n",
    "    pca_K2.fit(X_test_K)\n",
    "    PX_test_K = pca_K2.transform(X_test_K)\n",
    "    \n",
    "    #MSE\n",
    "    mse_lst.append(MSE(RG_K.predict(PX_test_K),Y_test_K))\n",
    "    \n",
    "    #Transform log(sale) back to sale\n",
    "    result_K = pd.DataFrame(np.exp(Y_test_K))\n",
    "    result_K[\"Predicted_sales\"] = np.exp(RG_K.predict(PX_test_K))\n",
    "    \n",
    "    #Obtain residual\n",
    "    residual_K = result_K[0]-result_K['Predicted_sales']\n",
    "    \n",
    "    #Get std for Normal distribution\n",
    "    s_K = residual.std()\n",
    "    \n",
    "    #Inventory Decision (Normal)\n",
    "    opt_dec_N_K=np.ceil(sct.norm.ppf(Under/(Under+Over))*s_K + result_K['Predicted_sales'])\n",
    "    #Inventory Decision (Exponential)\n",
    "    opt_dec_E_K=np.ceil((-result_K['Predicted_sales'])*np.log(1-(Under/(Under+Over))))\n",
    "    \n",
    "    #Inventory Decision (Empirical Distribution)\n",
    "    size_K = residual_K.shape[0]\n",
    "    step_K=1/size_K\n",
    "    jumps_K = [step_K*i for i in range(1,size+1)]\n",
    "    Sample_K = sorted(residual_K)\n",
    "    offset_K = inv(Sample_K,jumps_K,2/3)\n",
    "    opt_dec_B_K = np.ceil(result_K['Predicted_sales']+offset_K)\n",
    "    \n",
    "    #Out-of_sample profit\n",
    "    profit_lst_B_K = profit(result_K[0],opt_dec_B_K)\n",
    "    profit_B_lst.append(profit_lst_B_K.sum())\n",
    "    \n",
    "    profit_lst_N_K = profit(result_K[0],opt_dec_N_K)\n",
    "    profit_N_lst.append(profit_lst_N_K.sum())\n",
    "    \n",
    "    profit_lst_E_K = profit(result_K[0],opt_dec_E_K)\n",
    "    profit_E_lst.append(profit_lst_E_K.sum())\n",
    "    \n",
    "    max_profit_K = result_K[0].sum()*(Price-Cost)\n",
    "    max_profit_lst.append(max_profit_K)\n",
    "    \n",
    "max_profit_lst = np.array(max_profit_lst)\n",
    "profit_N_lst = np.array(profit_N_lst)\n",
    "profit_E_lst = np.array(profit_E_lst)\n",
    "profit_B_lst = np.array(profit_B_lst)\n",
    "\n",
    "fraction_of_max_N = profit_N_lst/max_profit_lst\n",
    "fraction_of_max_E = profit_E_lst/max_profit_lst\n",
    "fraction_of_max_B = profit_B_lst/max_profit_lst\n",
    "\n",
    "dist_profit = [\"Normal\",\"Exponential\",\"Empirical\",\"Max\"]\n",
    "dist_frac = [\"Normal\",\"Exponential\",\"Empirical\"]\n",
    "col_name = [\"Dataset_\"+str(i) for i in range(1,k+1)]\n",
    "\n",
    "profit_lst = [profit_N_lst,profit_E_lst,profit_B_lst,max_profit_lst]\n",
    "profit_table = pd.DataFrame(profit_lst,index=dist_profit,columns=col_name)\n",
    "profit_table[\"mean_profit\"]=profit_table.mean(axis=1)\n",
    "profit_table[\"std_profit\"]=profit_table.std(ddof=1,axis=1)\n",
    "\n",
    "fraction_lst = [fraction_of_max_N,fraction_of_max_E,fraction_of_max_B]\n",
    "fraction_table = pd.DataFrame(fraction_lst,index=dist_frac,columns=col_name)\n",
    "fraction_table[\"mean_fraction\"]=fraction_table.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_table.to_csv(\".\\\\Model_Selection_Result\\\\4.3_Gradient_boosting.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
